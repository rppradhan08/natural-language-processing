{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a73d800",
   "metadata": {},
   "source": [
    "# [Custom Trained BERT for Q&A System](https://medium.com/analytics-vidhya/question-answering-system-with-bert-ebe1130f8def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d8642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\raj\\anaconda3\\lib\\site-packages (4.27.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4d3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ed7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5630335b298417aaa5aad55b7d19a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raj\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Raj\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55edf6b1c54d4f879b21a31e3f39c96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5cf862557342fe997d5f8a89fb8634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fb0fdada564c93b3c66c45d0390322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae371bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''What is Machine Learning?'''\n",
    "\n",
    "paragraph = ''' Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance \n",
    "                on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or \n",
    "                decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection \n",
    "                of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning \n",
    "                is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, \n",
    "                theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
    "                data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb25c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 3698, 4083, 1029, 102, 3698, 4083, 1006, 19875, 1007, 2003, 1996, 4045, 2817, 1997, 13792, 1998, 7778, 4275, 2008, 3274, 3001, 2224, 2000, 20519, 5335, 2037, 2836, 2006, 1037, 3563, 4708, 1012, 3698, 4083, 13792, 3857, 1037, 8045, 2944, 1997, 7099, 2951, 1010, 2124, 2004, 1000, 2731, 2951, 1000, 1010, 1999, 2344, 2000, 2191, 20932, 2030, 6567, 2302, 2108, 12045, 16984, 2000, 4685, 1996, 4708, 1012, 3698, 4083, 13792, 2024, 2109, 1999, 1996, 5097, 1997, 10373, 22910, 1010, 10788, 1997, 2897, 22841, 2015, 1010, 1998, 3274, 4432, 1010, 2073, 2009, 2003, 1999, 7959, 21369, 3468, 2000, 4503, 2019, 9896, 1997, 3563, 8128, 2005, 4488, 1996, 4708, 1012, 3698, 4083, 2003, 4876, 3141, 2000, 15078, 6747, 1010, 2029, 7679, 2006, 2437, 20932, 2478, 7588, 1012, 1996, 2817, 1997, 8045, 20600, 18058, 4725, 1010, 3399, 1998, 4646, 13100, 2000, 1996, 2492, 1997, 3698, 4083, 1012, 2951, 5471, 2003, 1037, 2492, 1997, 2817, 2306, 3698, 4083, 1010, 1998, 7679, 2006, 4654, 24759, 6525, 7062, 2951, 4106, 2083, 4895, 6342, 4842, 11365, 2098, 4083, 1012, 1999, 2049, 4646, 2408, 2449, 3471, 1010, 3698, 4083, 2003, 2036, 3615, 2000, 2004, 16014, 3512, 25095, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32206ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'is', 'machine', 'learning', '?', '[SEP]', 'machine', 'learning', '(', 'ml', ')', 'is', 'the', 'scientific', 'study', 'of', 'algorithms', 'and', 'statistical', 'models', 'that', 'computer', 'systems', 'use', 'to', 'progressively', 'improve', 'their', 'performance', 'on', 'a', 'specific', 'task', '.', 'machine', 'learning', 'algorithms', 'build', 'a', 'mathematical', 'model', 'of', 'sample', 'data', ',', 'known', 'as', '\"', 'training', 'data', '\"', ',', 'in', 'order', 'to', 'make', 'predictions', 'or', 'decisions', 'without', 'being', 'explicitly', 'programmed', 'to', 'perform', 'the', 'task', '.', 'machine', 'learning', 'algorithms', 'are', 'used', 'in', 'the', 'applications', 'of', 'email', 'filtering', ',', 'detection', 'of', 'network', 'intruder', '##s', ',', 'and', 'computer', 'vision', ',', 'where', 'it', 'is', 'in', '##fe', '##asi', '##ble', 'to', 'develop', 'an', 'algorithm', 'of', 'specific', 'instructions', 'for', 'performing', 'the', 'task', '.', 'machine', 'learning', 'is', 'closely', 'related', 'to', 'computational', 'statistics', ',', 'which', 'focuses', 'on', 'making', 'predictions', 'using', 'computers', '.', 'the', 'study', 'of', 'mathematical', 'optimization', 'delivers', 'methods', ',', 'theory', 'and', 'application', 'domains', 'to', 'the', 'field', 'of', 'machine', 'learning', '.', 'data', 'mining', 'is', 'a', 'field', 'of', 'study', 'within', 'machine', 'learning', ',', 'and', 'focuses', 'on', 'ex', '##pl', '##ora', '##tory', 'data', 'analysis', 'through', 'un', '##su', '##per', '##vis', '##ed', 'learning', '.', 'in', 'its', 'application', 'across', 'business', 'problems', ',', 'machine', 'learning', 'is', 'also', 'referred', 'to', 'as', 'predict', '##ive', 'analytics', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "inputs = encoding['input_ids']  #Token embeddings\n",
    "sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbc70d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc5ba130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7542, -4.3813, -6.5904, -7.5645, -8.9276, -8.6470, -5.7542, -0.3306,\n",
       "         -4.4684, -2.9009,  0.3908, -5.2133,  2.5332,  5.5022,  5.3616,  0.7822,\n",
       "         -0.0102,  4.9764, -2.6878,  1.9115, -0.9204, -2.9185,  1.7439, -2.3654,\n",
       "         -2.0708, -1.7757, -0.9276, -1.9161, -4.9297, -3.0267, -4.8251, -4.6447,\n",
       "         -4.3884, -2.8900, -5.7541, -0.8635, -5.4572, -0.9168, -1.8347, -2.9211,\n",
       "         -1.5956, -4.0895, -5.9067, -3.0222, -4.5092, -6.8737, -4.8453, -6.3691,\n",
       "         -2.5550, -1.7856, -5.5590, -6.7446, -6.9368, -4.4873, -5.3093, -3.9420,\n",
       "         -3.4155, -3.1755, -7.3336, -4.3958, -4.2978, -6.7310, -5.0014, -5.0726,\n",
       "         -7.5880, -6.8129, -7.9276, -5.5676, -7.3021, -3.3388, -6.8694, -4.4947,\n",
       "         -7.5816, -5.6622, -7.4796, -6.8272, -4.7013, -7.7852, -4.5031, -5.9537,\n",
       "         -8.2277, -5.2420, -8.2161, -6.5695, -7.5492, -8.0937, -8.5280, -7.8790,\n",
       "         -4.4530, -6.2128, -7.7891, -5.4337, -5.3095, -7.8115, -5.4289, -7.6038,\n",
       "         -7.4653, -7.6292, -7.8791, -6.2018, -7.2688, -4.9777, -8.6266, -6.8585,\n",
       "         -6.5168, -8.6558, -7.4205, -8.7865, -7.1776, -8.0157, -3.4736, -6.6672,\n",
       "         -6.8591, -3.9177, -5.3252, -7.4094, -2.3485, -4.8078, -8.0448, -6.7822,\n",
       "         -4.6650, -6.8420, -4.1262, -3.5908, -7.5103, -6.0832, -8.3678, -6.4201,\n",
       "         -5.8888, -8.5604, -4.7988, -6.0192, -7.6938, -6.6952, -9.0054, -5.8340,\n",
       "         -8.7931, -6.1649, -8.2186, -8.5583, -7.4816, -5.7904, -8.4215, -5.7413,\n",
       "         -7.6079, -7.8089, -4.0023, -7.1492, -8.7508, -7.5744, -6.8736, -9.0363,\n",
       "         -7.9617, -7.7807, -6.3082, -8.4328, -8.7817, -7.9024, -5.9508, -8.4158,\n",
       "         -4.5610, -8.0885, -7.6387, -7.8114, -6.1618, -7.0643, -7.9057, -3.2194,\n",
       "         -7.3372, -7.8306, -7.8871, -8.3829, -6.5514, -7.6342, -4.9547, -6.9789,\n",
       "         -5.6476, -7.0480, -5.8994, -7.2272, -8.5335, -4.3086, -7.6419, -7.8336,\n",
       "         -6.5590, -6.2257, -7.6574, -6.4073, -1.6147, -7.3883, -5.3621, -7.4977,\n",
       "         -5.7544]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a8231cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end_logits'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08b8364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = torch.argmax(response[0])\n",
    "\n",
    "end_index = torch.argmax(response[1])\n",
    "\n",
    "answer = ' '.join(tokens[start_index:end_index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fdab34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the scientific study of algorithms and statistical models'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
