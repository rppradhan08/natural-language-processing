{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom NER based parser using Spacy3\n",
        "1. Downloading appropriate the skeleton of base [config_file](https://spacy.io/usage/training) as per the system requirement.\n",
        "\n",
        "\n",
        "2. Clone the source data [repo](https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git) to train the custom `ner` model.\n",
        "\n",
        "    ```bash\n",
        "    git clone https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git\n",
        "    ```\n",
        "\n",
        "3. Generate the `config.cfg` file using the `base_config.cfg` i.e. used for coniguring the Spacy Model parameters.\n",
        "\n",
        "    ```bash\n",
        "    python -m spacy init fill-config base_config.cfg config.cfg\n",
        "    ```\n",
        "\n",
        "\n",
        "\n",
        "4. Parse and convert source training data into `*.spacy` format.\n",
        "\n",
        "\n",
        "5. Train the blank `ner` based model on custom data using below command.\n",
        "\n",
        "    ```bash\n",
        "    python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy --gpu-id=0\n",
        "    ```\n",
        "    **Remark:** Here dev.spacy denotes the test data i.e. used for model evaluation\n",
        "\n",
        "\n",
        "6. Evaluate model performance on Unseen data."
      ],
      "metadata": {
        "id": "4ty9uEnXG7nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installing dependencies & importing packages"
      ],
      "metadata": {
        "id": "OedAf03GLEll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxqn-21ikswR",
        "outputId": "3a1e24ed-41dc-4063-ffd3-077c60659139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy_transformers\n",
            "  Downloading spacy_transformers-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy_transformers) (1.22.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy_transformers) (2.4.6)\n",
            "Collecting transformers<4.27.0,>=3.4.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from spacy_transformers) (3.5.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from spacy_transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (4.65.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.12)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (67.6.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.27.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.10.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->spacy_transformers) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->spacy_transformers) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->spacy_transformers) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->spacy_transformers) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->spacy_transformers) (3.11.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy_transformers) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy_transformers) (3.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (6.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.0->spacy_transformers) (1.3.0)\n",
            "Installing collected packages: tokenizers, spacy-alignments, huggingface-hub, transformers, spacy_transformers\n",
            "Successfully installed huggingface-hub-0.13.4 spacy-alignments-0.9.0 spacy_transformers-1.2.2 tokenizers-0.13.3 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.6.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.1\n",
            "    Uninstalling spacy-3.5.1:\n",
            "      Successfully uninstalled spacy-3.5.1\n",
            "Successfully installed spacy-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy_transformers\n",
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirement.txt"
      ],
      "metadata": {
        "id": "Fy1KCIL022Ra"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZNNjdmVlBIm"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNwiGFgBp7rc",
        "outputId": "7b1657ea-ae2b-4029-9b32-2f71136e38da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0uEN2q0me9L",
        "outputId": "39a42921-c3ce-4441-8698-17cc7da52d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UTF-8\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj4juiWMme_q"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facVFqxsm5au"
      },
      "source": [
        "After adding above 2 lines bash commands should work as expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvHFuWArlNkl",
        "outputId": "0f0c8609-997e-432a-dd92-a43307a25845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Apr 12 08:50:24 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    27W /  70W |    397MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Checking GPU configuration\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Donloading and preparing the `base_config.cfg` file"
      ],
      "metadata": {
        "id": "INuEb8uUQSJD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd_2iHjalm7Z",
        "outputId": "1800f513-a16e-453a-e591-e70c3046e788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-12 08:57:00.842471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume\n",
            "Parser/data/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config '/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/data/base_config.cfg' '/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/data/config.cfg'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading the source data and preparing it for model training."
      ],
      "metadata": {
        "id": "z_BeoO_3LYp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7SulmVVlmdg"
      },
      "outputs": [],
      "source": [
        "cv_Data = json.load(open(r'/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/data/train_data.json','r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MTnnmHDlmxf",
        "outputId": "7f8b42a2-574b-44ac-8fc1-32a31b6cf59b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cv_Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj7sRcLqlm3f",
        "outputId": "7b8fb2a2-f2ce-4c5b-d4c7-a838789e3c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [[1749, 1755, 'Companies worked at'],\n",
              "   [1696, 1702, 'Companies worked at'],\n",
              "   [1417, 1423, 'Companies worked at'],\n",
              "   [1356, 1793, 'Skills'],\n",
              "   [1209, 1215, 'Companies worked at'],\n",
              "   [1136, 1247, 'Skills'],\n",
              "   [928, 932, 'Graduation Year'],\n",
              "   [858, 889, 'College Name'],\n",
              "   [821, 856, 'Degree'],\n",
              "   [787, 791, 'Graduation Year'],\n",
              "   [744, 750, 'Companies worked at'],\n",
              "   [722, 742, 'Designation'],\n",
              "   [658, 664, 'Companies worked at'],\n",
              "   [640, 656, 'Designation'],\n",
              "   [574, 580, 'Companies worked at'],\n",
              "   [555, 572, 'Designation'],\n",
              "   [470, 493, 'Companies worked at'],\n",
              "   [444, 468, 'Designation'],\n",
              "   [308, 314, 'Companies worked at'],\n",
              "   [234, 240, 'Companies worked at'],\n",
              "   [175, 198, 'Companies worked at'],\n",
              "   [93, 136, 'Email Address'],\n",
              "   [39, 48, 'Location'],\n",
              "   [13, 37, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_Data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRtIyYyalm--"
      },
      "outputs": [],
      "source": [
        "def get_spacy_doc(file, data):\n",
        "    nlp = spacy.blank('en')\n",
        "    db = DocBin()\n",
        "    \n",
        "    for text, annot in tqdm(data):\n",
        "        doc = nlp.make_doc(text)\n",
        "        annot = annot['entities']\n",
        "        \n",
        "        ents = []\n",
        "        entity_indices = []\n",
        "        \n",
        "        for start, end, label in annot:\n",
        "            skip_entity = False\n",
        "            for idx in range(start, end):\n",
        "                if idx in entity_indices:\n",
        "                    skip_entity = True\n",
        "                    break\n",
        "            if skip_entity==True:\n",
        "                continue\n",
        "\n",
        "            entity_indices = entity_indices + list(range(start, end))\n",
        "\n",
        "            try:\n",
        "                span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            if span is None:\n",
        "                err_data = str([start, end]) + \"    \" + str(text) + \"\\n\"\n",
        "                file.write(err_data)\n",
        "            else:\n",
        "                ents.append(span)\n",
        "\n",
        "        try:\n",
        "            doc.ents = ents\n",
        "            db.add(doc)\n",
        "        except:\n",
        "            pass\n",
        "            \n",
        "    return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExE6BkHMlUaq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(cv_Data, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_GElug6tPlJ",
        "outputId": "6331e635-9352-467f-e958-d006f1a0bae6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 140/140 [00:02<00:00, 64.84it/s]\n",
            "100%|██████████| 60/60 [00:00<00:00, 62.41it/s]\n"
          ]
        }
      ],
      "source": [
        "file = open(r\"/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/error.txt\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "db_train = get_spacy_doc(file, train)\n",
        "db_train.to_disk(r'/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/train_data.spacy')\n",
        "\n",
        "db_test = get_spacy_doc(file, test)\n",
        "db_test.to_disk(r'/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/test_data.spacy')\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model training"
      ],
      "metadata": {
        "id": "McpKQ4NJQg3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AekxUPxtcJ1",
        "outputId": "7349dcb3-d0f9-48fc-9384-aca08637a048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-12 09:12:45.287164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Created output directory: /content/drive/MyDrive/Colab\n",
            "Notebooks/Work/Gembo/NER based Resume Parser/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: /content/drive/MyDrive/Colab\n",
            "Notebooks/Work/Gembo/NER based Resume Parser/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-04-12 09:12:56,039] [INFO] Set up nlp object from config\n",
            "[2023-04-12 09:12:56,050] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2023-04-12 09:12:56,053] [INFO] Created vocabulary\n",
            "[2023-04-12 09:12:56,054] [INFO] Finished initializing nlp object\n",
            "Downloading (…)lve/main/config.json: 100% 481/481 [00:00<00:00, 82.4kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 4.03MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 1.08MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 19.1MB/s]\n",
            "Downloading pytorch_model.bin: 100% 501M/501M [00:01<00:00, 296MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-04-12 09:13:31,986] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        2923.28   1593.73    0.08    0.04    1.77    0.00\n",
            "  0      10        9592.37  13119.77    0.08    0.04    1.77    0.00\n",
            "  0      20       16333.08  10672.13    0.09    0.04    1.77    0.00\n",
            "  0      30        5033.71  11803.56    0.00    0.00    0.00    0.00\n",
            "  0      40       14727.48   4068.42    0.00    0.00    0.00    0.00\n",
            "  1      50        2711.76   3099.51    0.00    0.00    0.00    0.00\n",
            "  1      60        8707.19    926.41    0.00    0.00    0.00    0.00\n",
            "  1      70        4122.11    962.84    0.00    0.00    0.00    0.00\n",
            "  1      80        2416.74   1500.24    0.00    0.00    0.00    0.00\n",
            "  1      90       14700.32   2152.73    4.98   63.33    2.59    0.05\n",
            "  2     100        5633.25   2496.88    1.92    8.00    1.09    0.02\n",
            "  2     110       15512.27   1329.79    0.00    0.00    0.00    0.00\n",
            "  2     120       17090.66   1611.81   11.64   52.17    6.55    0.12\n",
            "  2     130        9270.85   1577.44   23.92   56.92   15.14    0.24\n",
            "  2     140         871.06   1786.42   29.21   36.95   24.15    0.29\n",
            "  3     150       12062.63   2257.79   16.67   36.74   10.78    0.17\n",
            "  3     160       16849.83    964.70   20.19   84.85   11.46    0.20\n",
            "  3     170        3595.62    961.25   14.97   41.36    9.14    0.15\n",
            "  3     180        2781.39   1244.37   26.90   54.36   17.87    0.27\n",
            "  3     190        4253.76   1915.12   30.51   34.18   27.56    0.31\n",
            "  4     200         849.30   1726.98   23.53   33.93   18.01    0.24\n",
            "  4     210         168.57    694.70   31.53   41.61   25.38    0.32\n",
            "  4     220         453.62    918.24   32.19   34.70   30.01    0.32\n",
            "  4     230        2294.28   1321.83   34.75   37.56   32.33    0.35\n",
            "  4     240        2733.32   1875.55   24.55   35.77   18.69    0.25\n",
            "  5     250        1293.34   1371.88   33.01   56.44   23.33    0.33\n",
            "  5     260         148.12    654.50   38.48   39.65   37.38    0.38\n",
            "  5     270        6771.12    982.72   34.09   30.96   37.93    0.34\n",
            "  5     280        3948.36   1301.64   39.91   44.33   36.29    0.40\n",
            "  5     290        4419.18   1797.36   44.00   39.76   49.25    0.44\n",
            "  6     300         276.03   1204.24   44.78   62.81   34.79    0.45\n",
            "  6     310        4068.97    771.51   44.00   40.41   48.29    0.44\n",
            "  6     320         652.12    930.46   40.92   40.51   41.34    0.41\n",
            "  6     330         757.60   1188.93   52.61   54.45   50.89    0.53\n",
            "  6     340         457.70   1779.59   50.48   44.86   57.71    0.50\n",
            "  7     350         721.90   1089.36   37.56   58.33   27.69    0.38\n",
            "  7     360       14756.79    896.67   45.00   49.19   41.47    0.45\n",
            "  7     370         424.53    917.09   50.58   41.43   64.94    0.51\n",
            "  7     380         445.23   1167.94   53.39   51.66   55.25    0.53\n",
            "  7     390        1246.69   1855.17   49.61   42.20   60.16    0.50\n",
            "  8     400         320.71    790.63   41.08   60.48   31.11    0.41\n",
            "  8     410         195.53    532.40   49.88   44.41   56.89    0.50\n",
            "  8     420         513.58    939.65   50.84   46.79   55.66    0.51\n",
            "  8     430         467.25   1197.64   52.24   55.62   49.25    0.52\n",
            "  8     440         323.75   1879.55   53.79   48.37   60.57    0.54\n",
            "  9     450         751.27    609.62   44.61   68.75   33.02    0.45\n",
            "  9     460         109.40    457.01   54.00   47.70   62.21    0.54\n",
            "  9     470         302.14   1005.21   47.83   44.91   51.16    0.48\n",
            "  9     480         897.09   1179.83   52.36   51.04   53.75    0.52\n",
            " 10     490         585.44   1769.61   55.18   48.99   63.17    0.55\n",
            " 10     500          30.13    547.47   48.14   68.51   37.11    0.48\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume\n",
            "Parser/output/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train '/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/data/config.cfg' --output '/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/output' --paths.train '/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/train_data.spacy' --paths.dev '/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/test_data.spacy' --gpu-id=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Loading the base model and test the model on unseen data"
      ],
      "metadata": {
        "id": "J81LgHA2QqtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(r'/content/drive/MyDrive/Colab Notebooks/Work/Gembo/NER based Resume Parser/output/model-best')"
      ],
      "metadata": {
        "id": "nOHJU9Hj0s2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak_uLBauvQug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50677dc-eff4-4afd-c2c6-6d9865daeef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raj. ------------> Name\n",
            "ML Engineer ------------> Designation\n",
            "2 years ------------> Years of Experience\n"
          ]
        }
      ],
      "source": [
        "doc = nlp('My name is Raj. I work as a ML Engineer at GEMBO. I have 2 years of experience')\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \"------------>\", ent.label_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}